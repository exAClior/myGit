#+TITLE: Learning notes for ai on udacity

* <2018-10-27 Sat>

** Adaptation of Univariate Plots

*** use of barplot 
    instead of the counts we plot the mean of a value 
    we may also add error bars

*** Use of pointplot 
    if do not like bars, can use plot points to make things clear

*** adapted histogram 
    by changing the weight of each element can plot the density instead of count

**  line plots 
    want to emphasis the connection between change of one variable versus another 
    e.g stock value against time 
    use errorbar() note, need to sort the x values

***  Group continuous x variables 
     use bin edges 
     pd.cut()
     datafram.groupby()

***  may also achieve by using the rolling method in pandas' rolling window

[[https://stackoverflow.com/questions/20144529/shifted-colorbar-matplotlib][Good Color Map Reference]]

** Swarm plot
   same result of jittering , but the displacement is not random
   place dots as close to their original value as possible without overlap

** Rugplot
   displace density of points on axes

** Stripplot like 
* <2018-10-26 Fri>

**  scatterplots and correlation

***  correlation
     Pearson coefficient : r , how one variable changes w.r.t another

***  use of functions

****  scatter()
      plt.scatter(data = , x = , y = )

****  regplot()
      sb.regplot(data , x = , y = ) plots with regression line
  
** Overplotting Transparency and Jitter

***  Problem
****  Too many data points, the plot is now just a blob. 
      We sample part of the data and add transparency to the data dots 

**** Jitter
     When data points overlap and they take discrete values
     add random noise to their position in graph
     Too add transparency setting to regplot , need to pass it as one element
     of a dictionary of the variable scatter_kws

**  Heat Map
    Color denotes how many data points is in an area in the plot 
    hist2d() 
    keep an eye to the bin size

**  Violin Plots
    qualitative vs quantitative data 
    curve for each categorical group 
    seaborn.violonplot()

** Box plot 
   depicts outlier, max, q3 , median , q1 and min from top to bown 
   seaborn.boxplot()

** Cluster Bar Charts 
   seabon.heatmap()
   countplot() can also differentiate two different subgroup with in each column
   just provide with 'hue' parameter

** Faceting 
   different subset of data , create same kind of plot 
   remember to fix axes to be the same for these plots 
   g =  sb.FacetGrid()
   g.map () to determine what plot you need to do 
* <2018-10-25 Thu>

**  Scales and Transformations continuted 
* <2018-10-24 Wed>

**  Tidy data

*** Def
    each variable is a column
    each unit of observation is a row
    the observations of same units form a table

** Bar chart

***  depict the distribution of a categorical variable

***  we use matplotlib and seaborn to visualize data

***  countplot() to plot bar chars
     sb.countplot(data = variable_data, x/y = 'column_name')
     use [[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.api.types.CategoricalDtype.html][pandas.api.types.CategoricalDtype]] to generate an order categorical data 
     type made up of column names
     use plt.xticks(rotation = degrees) to rotate the x labels

** How to create Relative Frequency 
   one way is to change the label for frequency counts by manually calculating the 
   max frequency of one label on the other axis
   plt.yticks(values on y axis, label on that pos on y axis)


*** To maintain some sort of order 
    var_order = df['type_string'].value_counts().index
    returns a list of indexs for each row that are sorted by "type_string' value

***  Or you may display the percentage on each bar 
     use the matplotlib.pyplot.text() function
** Count missing data

***  use seaborn.barplot() see documentation for specific use
     this is for the use of summarized data, in other words
     necessary stats info is already gathered

** Pie Chart
   Show how data group proportion distribution is broken down into
   data group is no more than 4
   plt.pie(sorted_counts, labels = sorted_counts.index, startangle = 90,
        counterclock = False);
   note, the data 'sorted_counts' need to be already summarized
   wedgeprops = {'width' : 0.4} -> argument in pie() that removes the core
   of the pie and thus creating a pie chart

** Histogram,
   it is like probability distributions
   sb.hist()
   change bin size either by providing a single value or a list of 
   equally spaced numbers

*** distplot 
    plots the distribution plot by default

** Figures , Axes, and Subplots

***   How a graph is drawn in matplotlib
      first you need to create figure object, then you create axes object, finally 
      you plot the graph in axes

***  To create axes 
     use add_axes()
     to use this axes, in countplot(...., ax = ax )
     plt.gca() get current axes
     fig.get_axes() get the list of axes
     fig.add_subplot()  approximately equal to plt.subplot() 
     plt.subplots() create multiple subplots

** Choosing a plot for discrete data

***  use rwidth parameter with plt.hist() 
     plot bars separately

**  Descriptive Stats, Outliers, AXis Limits

***  plt.xlim({a,b}) 
     zooms in to the histogram

** Scales and Transformations

***  log-normal distributed
     when the value is taken the log, the distribution is normally distributed
* <2018-10-20 Sat>

** Why use Pandas
   to analyze your data set, such that it matches your machine learning algo's
   requirement

** Creating Pandas Series

*** To import 
    import pandas as pd 

*** To create 
    var = pd.Series(data, index)

*** What is a series 
    one d array that holds many data types

***  series special points
     index of series do not just have to be numbers, they can be strings
     much like in a dictionary

*** What meta data about a series 
    var.shape 
    var.ndim : how many dimension
    var.size : how many elements in there 
    var.values
    var.index

** Access and deleting elements in pandas series

***  access through both index or number index 
     var[0] will return the first data in the series 
     but when there is ambiguity, i.e , when the index itself is also int
     use var.loc[index] to access via index 
     use var.iloc[int index] to access via integer index , i.e like a normal array

***  delete item 
     var.drop(index) : deletes the index withouth modifying original series
     and returns a modified array 
     var.drop(index, inplace  = True), modifies the original series

** Arithmetic Operations on pandas series

*** arithmetic operations 
    works just like in an ndarray in numpy
    but you have to take care that the operation you do must be compatible with 
    all data types in that series

** Creating Pandas Dataframes
  
*** what is a dataframe
    it is like a spreadsheet in excel 
    
*** How to create  
   pd.DataFrame(item)
   item is in the form of dictionary of pd Series
   the row indices will be the union of two indexs,
   for the item that does not contain some index, we will palce NaN as the value

**** What if we do not have index
     pandas use 0 ,1 ,2 .... as default value

**** What if we want to create only part of that dict
     bob_shopping_cart = pd.DataFrame(items, columns=['Bob'])
     bob_shopping_cart = pd.DataFrame(items, columns=['Bob'])
     specify which item or index in the dict you want to create from

**** What if we want to specify row index oursleves
     df = pd.DataFrame(data, index = ['label 1', 'label 2', 'label 3'])

**** What if we want to create DataFrame via a list of dictionaries 
     dictionary keys will be the column indices 
     row indices will not be defined, so default values kicks in

** Access and adding elements in DataFrame

*** Access
    var[ [list of column labels] ]
    var.loc[ [list of row labels] ]
    var[column index][row index] to access single element 
    Alert: column always have to be places in front of row

*** Adding

**** To add new column 
     var['new_label'] = [list of data]

**** Add new column via adding up other columns 
     var['new_label'] = var['old_label_1'] + var['old_label_2']

**** To add new row
     First create new DataFrame 
     then use old_frame.append()

**** To add new column that is part of the existing column at the end
     store_items['new watches'] = store_items['watches'][start:end]

**** To insert new column anywhere
     dataframe.insert(loc,label,data)
     note the location starts at 0 which in the row labels

**** To remove items

***** pop('column_index') 
      deletes columns

***** drop(['index'], axis = 0/ row, 1 / column)
      deletes both rows and columns

**** To rename label 
     store_items = store_items.rename(columns = {'bikes': 'hats'}) : changes column
     store_items = store_items.rename(index = {'store 3': 'last store'}) : changes row
     store_items = store_items.set_index('pants') : set row index to be data in a column

** Deal with NaN value

*** Detect and count

**** .isnull() 
     returns the same shape of data that indicates whether each place is null or not by a boolean 
     use multiple .sum() to count how many True (which means is NaN) there is in the entire DataFram
     each .sum() reduces the dimensionality of the DataFrame by 1

****  .count() 
      counts the non-NaN values

****  .drop(axis = 0/row , 1 /column, inplace = boolean )
      delete all columns or rows that contains NaN
      notice this does not modify the original DataFrame by default, if want change the inplace value

****  .fillna(value)
      fill all NaN with value provided

****  .fillna(method = 'ffill', axis = 0 /column, 1 / row )
      fille NaN with the value before them along the axis specified

****  .interpolate(method = 'linear', axis = )

** Loading Data into a Pandas DataFrame

***  To load CSV file 
     pd.read_csv('file_name')

*** General Information
    file_name.tail(N) : last N rows is displayed
    file_name.head(N) : first N rows is displayed
    file_name.isnull().any() : check if any column had NaN values
    file_name.describe() : gives statistical description on some data
    file_name['column index'].describe() : describes a single column
    file_name.groupby() : collects data that has the same data in some columns 
    and then form a new DataFrame and does calculation on them
* <2018-10-19 Fri>

** Slicing ndarrays 
   X[start:end]
   X[start:]

*** Slicing only creates a new label -> the variable name, but not a new ndarray
    to create a new nparray, use copy()

***  to get diagonal 
     use np.diag(ndarray, k = N)
     N is the number of element above or below the diagonal

***  to get unique elements in the array
     np.unique

***  np.sort(x)
     leaves x unchanged

***  x.sort()
     changes the array x itself

***  access elements in an array that satsifies a boolean expression
     place the boolean expression in the index part
     eg: x[ bool expression]
     
*** np.sort(x,axis = ?)
    sort rank 2 arrays, the axis argument tells the program 
    whether to sort everything row wise or column.

** Arithmetic operations and Broadcasting

*** broadcasting 
    it allows you to do arithmetic operations of smaller size arrays
    to bigger ones
    behind the scene, python broadcasts the smaller array/ number into the same
    shape as the larger one 
    [[https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html][broadcasting rules]]

***  numpy also has awesome functions that obtian stats info of an ndarray 
* <2018-10-17 Wed>

** using anaconda
   conda install 'package_name'
   conda search 'package_name_approx'

** Creating and using  another encironment
   conda create -n env_name [list of packages] [python= version_number]
   source activate my_env
   source deactivate
   conda env export > environment.yaml : export the current enviroment into a file
   conda env create -f environment.yaml : load environment from a file
   conda env remove -n env_name : remove an environment

** Things about using an environment 
   create two env for python2 and python3 for general use
   pip freeze > requirements.txt : does the same job as conda env export 
   [[https://jakevdp.github.io/blog/2016/08/25/conda-myths-and-misconceptions/][Extra Learning on Conda]]

** Jupyter note book 

*** Literate programming 
    documentation is written as a narrative alongside the code

*** How notebooks work 
    server renders notebook file and then send it via http&websockets to user
    the code part of the notebook is sent to the kernel
    kernel can not only interprete one language but many

*** jupyter short cuts
    shift+tab to have function documentation
    shift+tab continutously twice to bring up help document

*** Markdown cell style 
    Use #, or ##, or ### before text for different size of header
    [Text] (URL)
    _text_ or *text* to italics
    __text__ or **text** for bold 
    wrap code around with '''   '''
    or indent all code with 4 spaces
    For math block , wrap the entire block with $$  $$, then follow latex rules
    For math equation, wrap the equation with $ $
    
    [[https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet][Cheat sheet]]

*** Short cuts
    use Y to make a block code 
    use M to make a block markdown 
    use H to call out the help menu 
    use L to turn on and off code line number
    use D D to delete a cell
    shift + control + p to access control palette

*** Magic keywords
    gProbably only works in python kernel mode
    % magic word works for a line 
    %% magic word works for a cell
    example of magic word : timeit , times the code 
    The use of matplotlib inline to render a plot is not very clear, read more while coding 
    %pdb for debugging
    [[https://ipython.readthedocs.io/en/stable/interactive/magics.html][Magic word list]]

*** Convert notebooks
    use jupyter nbconvert --to file_format ipynb_file_name
    convert ipynb file into other format, because ipynb is json, so 
    jupyter nbconvert notebook.ipynb --to slides : convert to slides
    jupyter nbconvert notebook.ipynb --to slides --post serve : convert to slides and then serve

** Intro to Numpy

*** Why numpy
    numpy is faster than plain python if you use built in function in numpy
    numpy arrays can only hold one type of data at a time

***  Creating and saving numpy ndarrys
     np.array does up casting if the elements in the array are some ints and some floats to keep calculation precession
     x = np.array([1.5, 2.2, 3.7, 4.0, 5.9], dtype = np.int64) : assigns specific data type to the array
     np.save('my_array', x) : saves the ndarray 
     y = np.load('my_array.npy') : loads the ndarray

*** Use built-in functions to create ndarrays
    np.eye create identity matrix
    np.diag, create diagonal matrix
    np.full create array with specific dimension with specific value 
    np.arange create a linear array
    np.linspace require both start and end points
    np.reshape convert rank 1 array to another rank 2 array
    np.random.random ,random float nubmer array with specific shape
    np.random.randint ,
    np.random.normal, array with specific shape whose values follow normal distribution with specified distribution property
    np.zeros() creates zero array
    np.ones()

*** Accessing, Deleting and Inserting into ndarrays 
    use np.delete()
        np.insert()
	np.append()
	np.vstack() stack one array above another
	np.hstack() stack one array horizontally 
* <2018-10-16 Tue>

** Create one environment to each project 
   Use Conda, more specifically, : conda create

** Copy your current dependency for others to follow
   pip freeze > requirement.txt
* <2018-10-15 Mon>

** encapsulation
   Grouping different functions into a class
   This hides the implementation of different functions
** creater function
   __init__(arguments)
** self argument
   If you want to access attributes of a class, you would have to include
   the self as one argument
** 
* <2018-10-13 Sat>

**  Use argparse() to write user-friendly command line interface

** 
* <2018-10-12 Fri>
** Reading and Writing File
*** open("filename",mode of opening) returns a file object
****  this object that we operate them
**** if you forget to close file, you can run out of file handle thus no longer be able to open new files
****  if you open file with "w" mode, you delete everything it contains before
****  if you want to append use "a" mode
*** with .... as ..... 
**** with open('my_path/my_file.txt', 'r') as f:
**** automatically closes f outside the scope
****  but things decleared inside the with scope is not limited to exist before with .... as ends:
*** Use readline() to read line by line in python
*** use strip() to remove '\n'
** Import Local scripts
***  import "url to otherfiel/name of the file"
***  Note, when we import other file, any thing that is ran in that file will be run at the same time when we run our file
***  If you want to access object num in another  file : anotherfile, use : anotherfile.name
***  the same is with functions
***  use import lonenamefile as abrev, to simplify the calling function process
***  if there is executing block of code in a file, put them under the if __name__ = "__main__" block of code
**** or first put them under def  main(): then do if __name__ == "__main__" : main()
****  this ensures that the block of code will only be executed if the file is been called upon, not imported.
****  when being imported, the __name__  = nameoffile
****  if called directly upon, __name__ = "__main__"
**  [[https://docs.python.org/3/library/][Python Standard Library]]
***  random.choice()
****  choose random object from a collection of data
***  random.sample(container name, number)
****  pick randomly a number of objects from a container
** Techniques for Importing Modules
***  import just few functions
****  from module_name import object_name1, name 2, name 3 
      from module_name import object_name as abbrev
**  Third-party libraries
***  import third party libraries after standard library
***  include "requirement.txt" with yoour code so that collaborators know which libraries they need to install
***  include versions is good practise
***  use pip install -r requirement.txt to install these requirements
* <2018-10-08 Mon>
** Accessing Error Messages
***  use "except .... as var_name" to store the error message into a string
***  if you want to catch any exception in general use keyword "Exception"
** Scripting with Raw Input
*** eval(" a string") evaluates the string as a line of python code
** Errors and Exceptions
*** try statement: runs a line of code
***  except statement : if exception is raised, run the following code
***  else statement: in the same indent as except statement, if no exception is raised, run that
***  finally statement: same indent as try, it is excecuted no matter what the previous things do, even if you ask the previous things to close the program
*** [[https://stackoverflow.com/questions/11551996/why-do-we-need-the-finally-clause-in-python][Why do we need finally ]]
***  except (tuples of exception you want this to catch)
***  may even use multiple except for one try to act differently according to different errors
* <2018-10-07 Sun>
** Iterators and Generators
*** Iterables: OBJECTS that gives you one element at a time when operated on it properly
****  eg; list , the return value of enumerate
***  iterator : what is created by generators
**** it represents a stream of data , which is different from list, a collection of data
*** generators :
**** Like functions that return a list, instead uses key word "yield" and return an iterator
**** use generators instead of list because we can generate/access the wanted element one at a time thus puts less stress on memoery [[https://softwareengineering.stackexchange.com/questions/290231/when-should-i-use-a-generator-and-when-a-list-in-python/290235][Why Generator]]
*** sq_list = [x**2 for x in range(10)]  # this produces a list of squares            sq_iterator = (x**2 for x in range(10))  # this produces an iterator of squares
** Lambda function
***  put the following into where you need the lambda function to go,i.e as a parameter of another function
****  lambda "parameters.....": what you need to do with these parameters
****  If you actually need to call this function later, assign name to this lambda function : func_name = lambda parameter : operation
** Scope
*** If a function tries to modify a global variable or something that is defined outside of the func, error occurs
** Functions
*** def func_name(arguments):
*** You may also do this when calling a function func(para1 = 10, para2=5), this is called pass by name
* <2018-10-06 Sat>

** For loops

*** range(start = 0, stop, step =1), if sepcify two variable, the first variable is start
*** string: lower() -> change all character into lower
*** string: replace("c1","c2") replace c1 into c2 in the string called upon
***  if range(start,end) start > end , returns empty list
***  dict().items() return a tuple of key and value in the dictionary
** Break, Continue
*** break breaks out a loop entires
*** continue skips one iteration of a loop
** Zip and Enumerate
***  zip returns ITERATOR of the combined two lists, we need to use list() to convert the return value of zip into an actual list
***  *some_list unzips a list of tuples but you have to use it in conjunction with zip()
***  enumerate() returns both the index and item of an iterable data structure
*** to transpose a matrix do tuple(zip(*data)
** List comprehension
*** capitalized_cities = [city.title() for city in cities]
*** squares = [x**2 if x % 2 == 0 else x + 3 for x in range(9)]
*** passed = [name  for name in scores  if scores[name] >= 65  ]
* <2018-10-05 Fri>
** Lists and Membership Operators
*** If you use index -1 you get the last item, -2 second to last
*** let q3 be a list q3[3:6] slices 
*** python list can contain a mix of different data types
*** use key word "in" "not in" to determine whether a data is in a list or not
*** List is a mutable data strucvture  type but string is not
*** the other important quality is whether a data structure type is ordered or not
*** ordered or not depends on whether we can use the position of the element in a data structure to access them
** List Methods
*** Lists are likely to be pass by reference since one list which are pointed by two different variable names are mutated at the same time when one varies
*** for string, max operator compares the alphabetical order
*** sorted() sorts the data structure
*** string.join(..) joins string elements together connecting them with the string on which join is called upon
** Tuples
***  Like list but are immutable and ordered
** Sets
***  Unordered and unique elements, can create set from lists using set(list_name)
*** pop()
** Dictionary
*** store key and value pair
*** use "in" or ".get()" to check if a key is in the dict
*** dictionary keys must be immutable
*** can setup what if return if .get() fails to grab what you want
** Compund Data Structure
*** Can setup dictionary as value of another dictionary
* <2018-10-04 Thu>
** Integer and Floats
*** Use type(x) to look up the type of a variable
*** use int(x) to cast x into a data type
*** 
** String
*** String in python is immutable
*** + to combine string
*** * to multiply string
*** format() can be used to print designated outputs 
* <2018-10-03 Wed>
** Arithemetic operator 
*** to take power, use "**"
*** ^ does bitwise xor
*** "//" integer division, rounds the answer down 

























 





